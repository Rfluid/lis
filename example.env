# ENV: Specifies the current environment. This can be used to control behavior
#      that differs between development, testing, and production.
#      Possible values: "dev", "prod", "test" or "local".
ENV=dev


# LLM (Large Language Model) Configuration
#
# LLM_PROVIDER: Defines the provider for the main LLM used for generating responses.
#               Supported values include "ollama", "openai", "anthropic", "cohere", "gemini".
LLM_PROVIDER=ollama
# LLM_MODEL_NAME: The specific model name to be used from the chosen LLM_PROVIDER.
#                 Examples: "mistral", "gpt-4o", "claude-3-opus-20240229", "command-r-plus", "gemini-1.5-pro-latest".
LLM_MODEL_NAME=mistral
# LLM_API_KEY: Your API key for the chosen LLM_PROVIDER. This is a sensitive credential.
LLM_API_KEY=1234
# LLM_TEMPERATURE: Controls the randomness of the LLM's responses. A value of 0 means
#                  more deterministic and focused output, higher values (e.g., 0.7) for more creativity.
LLM_TEMPERATURE=0
# LLM_STOP: A comma-separated list of strings that, when encountered, will stop the LLM
#           from generating further tokens. Useful for controlling output length or format.
LLM_STOP=null
# LLM Kwargs are passed via
# LLM_ARG_SOME_KEY=foo
# and is normalized to
# { "some_key": "foo" }
# All kwargs passed are merged.

# Tool Evaluator LLM Configuration: Used by the agent to decide which tool to use next.
# TOOL_EVALUATOR_LLM_PROVIDER: Provider for the LLM used in tool evaluation. Defaults to LLM_PROVIDER.
TOOL_EVALUATOR_LLM_PROVIDER=ollama
# TOOL_EVALUATOR_LLM_MODEL_NAME: Model name for the tool evaluator. Defaults to LLM_MODEL_NAME.
TOOL_EVALUATOR_LLM_MODEL_NAME=mistral
# TOOL_EVALUATOR_LLM_API_KEY: API key for the tool evaluator LLM. Defaults to LLM_API_KEY.
TOOL_EVALUATOR_LLM_API_KEY=1234
# TOOL_EVALUATOR_LLM_TEMPERATURE: Temperature for the tool evaluator LLM. Defaults to LLM_TEMPERATURE.
TOOL_EVALUATOR_LLM_TEMPERATURE=0
# TOOL_EVALUATOR_LLM_STOP: Stop sequences for the tool evaluator LLM. Defaults to LLM_STOP.
TOOL_EVALUATOR_LLM_STOP=null
# Tool Evaluator LLM Kwargs are passed via
# TOOL_EVALUATOR_LLM_ARG_SOME_KEY=foo
# and is normalized to
# { "some_key": "foo" }
# All kwargs passed are merged.

# SUMMARIZE LLM Configuration (for the summarization step)
#
# SUMMARIZE_LLM_PROVIDER: LLM provider specifically for summarization. If unset,
# falls back to LLM_PROVIDER (see code: LLMProvider(os.getenv("SUMMARIZE_LLM_PROVIDER") or LLM_PROVIDER)).
# Supported values: 'ollama', 'openai', 'anthropic', 'cohere', 'gemini'.
SUMMARIZE_LLM_PROVIDER=ollama
# SUMMARIZE_LLM_MODEL_NAME: Model name used by the summarizer. If unset, falls back to LLM_MODEL_NAME.
# Example for Ollama: 'mistral'; for OpenAI: 'gpt-4o-mini'.
SUMMARIZE_LLM_MODEL_NAME=mistral
# SUMMARIZE_LLM_API_KEY: API key for the summarizer model. If unset or empty,
# falls back to LLM_API_KEY (SecretStr wrapping per your code).
SUMMARIZE_LLM_API_KEY=1234
# SUMMARIZE_LLM_TEMPERATURE: Temperature for the summarizer model. If unset,
# falls back to LLM_TEMPERATURE. Use 0 for deterministic summaries.
SUMMARIZE_LLM_TEMPERATURE=0
# SUMMARIZE_LLM_STOP: Optional comma-separated list of stop sequences for the summarizer.
# Leave empty to disable. Example: "</s>,###"
# Your code splits on commas into a Python list when non-empty.
SUMMARIZE_LLM_STOP=
# Summarize LLM Kwargs are passed via
# SUMMARIZE_LLM_ARG_SOME_KEY=foo
# and is normalized to
# { "some_key": "foo" }
# All kwargs passed are merged.

# Text Embedding LLM Configuration: Used to convert text into vector embeddings for the RAG system.
# TEXT_EMBEDDING_PROVIDER: The provider for the text embedding model. Defaults to LLM_PROVIDER.
TEXT_EMBEDDING_PROVIDER=ollama
# TEXT_EMBEDDING_MODEL_NAME: The specific model name for text embeddings.
TEXT_EMBEDDING_MODEL_NAME=models/text-embedding-004
# TEXT_EMBEDDING_API_KEY: API key for the embedding model. Defaults to LLM_API_KEY.
TEXT_EMBEDDING_API_KEY=1234

# Calendar Configuration
# CALENDAR_PROVIDER: Specifies the calendar service to integrate with. Currently only "google" is fully supported.
CALENDAR_PROVIDER="google"
# GOOGLE_SERVICE_ACCOUNT_FILE: The filename of your Google service account credentials JSON file,
#                              located in the 'data' directory.
GOOGLE_SERVICE_ACCOUNT_FILE="service-account.google.json"
# CALENDAR_ID: The ID of the primary calendar Lis will interact with for creating,
#              updating, and deleting events. This is typically an email address for Google Calendar.
CALENDAR_ID="dsjf9qe8fj129fjef0h088129ffdshf9128399hsjj91289f919jfdsh8912gl1d@group.calendar.google.com"

# Data and Prompts Directory Configuration
#
# DATA_DIR: Path to the directory where application data files (like calendar credentials) are stored.
#           Use `/app/data` for Docker environments or `data` for local execution.
DATA_DIR=data
# PROMPTS_DIR: Path to the directory containing prompt templates for the LLM.
#              Use `/app/prompts` for Docker environments or `prompts` for local execution.
PROMPTS_DIR=prompts

# Frontend API URL
# API_URL: The base URL where the backend FastAPI application is accessible.
#          The Streamlit frontend will use this to communicate with the backend.
API_URL=http://localhost:8000

# Database Configuration (for Agent's Checkpointer)
#
# POSTGRES_URI: Connection string for the PostgreSQL database. This is used by LangGraph
#               for checkpointing agent states. If running with Docker Compose, this will be
#               overridden by the Docker Compose file to point to the `postgres` service.
#               Example for local: postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable
POSTGRES_URI=postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable

# Vector Database (Milvus) Configuration for RAG
#
# MILVUS_URI: The URI for your Milvus vector database instance.
#             Example for local: http://localhost:19530
#             Example for Docker Compose: http://milvus:19530
MILVUS_URI=http://localhost:19530
# MILVUS_USERNAME: (Optional) Username for Milvus authentication.
MILVUS_USERNAME=admin
# MILVUS_PASSWORD: (Optional) Password for Milvus authentication.
MILVUS_PASSWORD=your_password
# MILVUS_COLLECTION: The name of the collection within Milvus where documents will be stored.
MILVUS_COLLECTION=your_collection_name

# Switches between `evaluate_tools` -> `generate_response` (two LLM calls)
# and `evaluate_tools` with `generate_response`. Also changes the example
# file for `evaluate_tools` prompt to `evaluate_tools_parallel.example.md`
PARALLEL_GENERATION=false
